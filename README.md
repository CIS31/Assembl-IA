# Assembl-IA

Ce projet a pour but de capter les strat√©gies rh√©toriques, entendues comme les techniques d'expression et de communication, mises en ≈ìuvre par les d√©put√©s actifs lors des s√©ances parlementaires.   

Pour ce faire notre √©quipe s'est orient√©e vers la pipeline Azure suivante :  

![Demo](./assets/Fil%20rouge%20v2.png)

L'interface utilisateur est accessible via le lien : 
üîó https://assemblia-backend.azurewebsites.net/informations

## Job 0 : Webscrapping 

Dans le dossier dag se trouvent deux fichiers python permettant de r√©cup√©rer :  
- les derni√®res vid√©os de l'asssembl√©e nationale au format .mp4  
- les derniers comptes-rendus de s√©ances au format .xml  

Ces fichiers sont stock√©s dans le blob storage Azure et servent d'input pour les diff√©rents jobs ci-dessous.  
   
## Job 1 : Analyse vid√©o  
  
#### Pr√©sentation  

Ce job permet de traiter la vid√©o la plus r√©cente r√©cup√©r√©e suite au webscrapping.  

#### Fonctionnalit√©s

- ‚úÖ Lecture vid√©o frame par frame
- ‚úÖ D√©tection des visages
- ‚úÖ Si visage assez grand ‚Üí D√©tection des √©motions (les 2 classes majoritaires)
- ‚úÖ Annotation des r√©sultats sur la vid√©o en output
- ‚úÖ Cr√©ation d'un timeline (fichier CSV)

#### Pipeline Azure

- ‚úÖ Lecture des variables d'environnement contenues dans les param√®tres du job databricks
- ‚úÖ R√©cup√©ration de la derni√®re vid√©o pr√©sente sur le blob storage
- ‚úÖ Traitement
- ‚úÖ Enregistrement de la vid√©o annot√©e et de la timeline dans le blob storage
- ‚úÖ Enregistrement de la timeline dans postgres

#### D√©mo GIF 

Il s'agit d'un gif, la vid√©o au format .mp4 est disponible dans le dossier output

![Demo](./assets/video_vitrine.gif)

#### Mod√®les utilis√©s

- YOLO v8 : 
üîó https://yolov8.com/

- facial_emotions_image_detection : 
üîó https://huggingface.co/dima806/facial_emotions_image_detection

#### Evaluation des mod√®les 

- utilisation du dataset de test suivant :
üîó https://www.kaggle.com/datasets/ananthu017/emotion-detection-fer

- resultats : 
![Demo](./assets/testdumodelvideo.png)
  
| Emotion   | Pr√©cision |
|-----------|-----------|
| Angry     | 0.772     |
| Disgust   | 1.000     |
| Fear      | 0.838     |
| Happy     | 0.822     |
| Neutral   | 0.740     |
| Sad       | 0.943     |
| Surprise  | 0.928     |

Pr√©cision globale : **0.847**


## Job 2 : Analyse audio

#### Introduction
Ce projet met en ≈ìuvre un pipeline complet d'analyse audio, ax√© sur l'extraction et l'√©tude des caract√©ristiques prosodiques du langage parl√©, ainsi que sur la diarisation des locuteurs. L'objectif est de fournir des informations d√©taill√©es sur "qui a parl√© quand" et "comment" (en termes de hauteur et d'intensit√© de la voix), facilitant ainsi une compr√©hension approfondie des interactions vocales.

#### Objectifs de l'Analyse
Notre analyse audio vise √† atteindre les objectifs suivants :

* **Compter le nombre de locuteurs** distincts pr√©sents dans un enregistrement audio.
* R√©aliser la **Diarisation des Locuteurs** : identifier pr√©cis√©ment les segments o√π chaque locuteur a pris la parole (d√©terminer "qui a parl√© quand").
* Extraire et analyser l'**Intensit√©** (volume sonore) de la voix pour chaque locuteur.
* Extraire et analyser le **Pitch (F0)** (fr√©quence fondamentale / hauteur de la voix) pour chaque locuteur.
* G√©n√©rer une **Timeline de Prise de Parole** : visualiser graphiquement les p√©riodes d'activit√© vocale de chaque participant.

#### M√©thodologie

Le pipeline d'analyse est structur√© en plusieurs √©tapes cl√©s :

1.  **Chargement et Pr√©paration des Donn√©es :**
    * **Audio :** L'enregistrement audio est charg√© √† l'aide de la biblioth√®que `librosa`, garantissant une fr√©quence d'√©chantillonnage et un format mono coh√©rents pour l'analyse.
    * **Diarisation (via XML) :** Les segments de prise de parole des locuteurs sont import√©s depuis un fichier XML (avec une structure pr√©d√©finie ` <segment start="..." end="..." speaker="..."/>`). Ces donn√©es sont ensuite trait√©es pour √™tre utilis√©es dans l'analyse.

2.  **Conversion au Format RTTM :**
    * Les informations de diarisation extraites du fichier XML peuvent √™tre converties et export√©es au format standard **RTTM** (Rich Transcription Time Marked). Ce format est largement utilis√© dans le domaine du traitement de la parole pour repr√©senter les segments de locuteurs, facilitant l'interop√©rabilit√© et l'√©valuation.

3.  **Extraction des Caract√©ristiques Prosodiques :**
    * Pour chaque segment de parole identifi√© par la diarisation, les caract√©ristiques prosodiques suivantes sont extraites :
        * **Pitch (F0) :** La fr√©quence fondamentale de la voix est calcul√©e en utilisant `librosa.core.piptrack`. Des filtres sont appliqu√©s pour assurer la fiabilit√© des mesures de pitch (en excluant les valeurs avec une faible magnitude).
        * **Intensit√© :** L'√©nergie RMS (Root Mean Square) est calcul√©e via `librosa.feature.rms` et convertie en d√©cibels (dB), fournissant une mesure du volume sonore.
    * Ces caract√©ristiques sont extraites sous forme de **contours temporels** (l'√©volution des valeurs au fil du temps) et de donn√©es brutes pour des analyses statistiques.

4.  **Analyse et Agr√©gation des Donn√©es :**
    * Les donn√©es de pitch et d'intensit√© sont regroup√©es par locuteur.
    * Des statistiques descriptives cl√©s (moyenne, m√©diane, √©cart-type) pour le pitch et l'intensit√© sont calcul√©es pour chaque locuteur.
    * La dur√©e totale de parole de chaque locuteur est comptabilis√©e pour √©valuer leur contribution.

#### Sorties et Visualisation

Le projet g√©n√®re plusieurs types de sorties, principalement sous forme de fichiers CSV pour faciliter l'int√©gration avec des outils de visualisation ou d'analyse externe :

* **Fichier RTTM** (`.rttm`) : Diarisation des locuteurs au format standard.
* **Timeline des Locuteurs** (`timeline_data.csv`) : Un fichier CSV d√©taillant chaque segment de parole avec `speaker_label`, `start`, `duration` et `end`. Pour faciliter l'affichage graphique, une s√©lection des locuteurs les plus actifs (par exemple, le top 5) est g√©n√©ralement privil√©gi√©e pour la visualisation directe, mais toutes les donn√©es sont disponibles dans ce fichier.
* **Distributions Prosodiques** (`prosody_stats.csv`) : Un fichier CSV r√©capitulant les statistiques cl√©s (moyenne, m√©diane, √©cart-type) du pitch et de l'intensit√© pour chaque locuteur.
* **Contours de Pitch** (`pitch_contours.csv`) : Un fichier CSV contenant les donn√©es de s√©ries temporelles pour le contour de pitch (`speaker_label`, `time_s`, `pitch_hz`).
* **Contours d'Intensit√©** (`intensity_contours.csv`) : Un fichier CSV contenant les donn√©es de s√©ries temporelles pour le contour d'intensit√© (`speaker_label`, `time_s`, `intensity_db`).

Des fonctions de tra√ßage sont √©galement incluses pour g√©n√©rer des repr√©sentations visuelles (diagrammes de timeline, histogrammes de distribution, trac√©s de contours) directement si n√©cessaire.

#### Utilisation (Conceptuel)

Pour utiliser ce pipeline, vous devrez g√©n√©ralement :

1.  Avoir un fichier audio (ex: `.wav`).
2.  Disposer d'un fichier XML de retranscription associ√©.
3.  Ex√©cuter la classe d'analyse fournie en lui passant ces fichiers en entr√©e.
4.  Les fichiers de sortie CSV seront g√©n√©r√©s dans le r√©pertoire sp√©cifi√© (par d√©faut `./output/`).

#### Analyse Interactive et Visualisations

![prosodic_contour](./audio/output/prosodic_contours_speaker_x.png)

Pour une exploration interactive des donn√©es et la visualisation des diff√©rentes sorties graphiques (timeline, contours de pitch et d'intensit√©, distributions), un **Notebook Jupyter** est fourni :

* **`audio_analysis.ipynb`** : Ce notebook contient le code pas √† pas qui g√©n√®re les donn√©es export√©es et illustre comment cr√©er les diff√©rents graphiques mentionn√©s (timeline, contours, distributions de pitch et d'intensit√©) √† partir de ces donn√©es. Il sert de guide pratique pour comprendre le fonctionnement de l'analyse et interpr√©ter les r√©sultats visuellement.


![distribution_intensit√©](./audio/output/distribution_intensit√©.png)

## Job 3 : Analyse textuelle

#### Pr√©sentation

Cette brique du projet vise √† **d√©tecter les √©motions dans des textes en fran√ßais** (transcriptions audio, commentaires, scripts, etc.).  
Afin d‚Äôaligner la sortie textuelle sur l‚Äôaxe visuel, nous couvrons **7 √©motions** : Tristesse (`sad`), Peur (`fear`), Col√®re (`anger`), Neutre (`neutral`), Surprise (`surprise`), Joie (`joy`) et D√©go√ªt (`disgusted`).

#### Fonctionnalit√©s

- ‚úÖ Pr√©-traitement complet du texte (nettoyage, normalisation, tokenisation)
- ‚úÖ Classification des √©motions sur 7 classes
- ‚úÖ Export CSV contenant : timestamp, texte original, √©motion pr√©dite, score de confiance
- ‚úÖ Int√©gration directe dans la pipeline Azure (Databricks + Blob Storage + Postgres)

#### Pipeline Azure

1. Lecture des fichiers texte ou transcriptions stock√©s dans le **Blob Storage**  
2. **Databricks** appelle le notebook de pr√©diction NLP  
3. Les pr√©dictions sont :
   - stock√©es au format CSV dans le Blob Storage (dossier *output*)  
   - ins√©r√©es dans **Postgres** pour exploitation BI  
4. Les m√©triques d‚Äôex√©cution (latence, nombre de tokens) sont remont√©es √† **Azure Application Insights**

#### Mod√®le utilis√©

| Nom | Base | Type | Lien |
|-----|------|------|------|
| `assembl-ia/french_emotion_camembert-7cls` | CamemBERT-base | Fine-tune (7 √©motions) | üîó [Hugging Face (original)](https://huggingface.co/astrosbd/french_emotion_camembert) |

- **Fine-tuning** r√©alis√© sur un jeu de donn√©es √©quilibr√© de **5 033 phrases** (719 exemples/√©motion).  
- **Epochs** : 5 ‚ÄÉ‚ÄÉ‚Ä¢‚ÄÉ‚ÄÉ**Batch size** : 16 ‚ÄÉ‚ÄÉ‚Ä¢‚ÄÉ‚ÄÉ**LR** : 2e-5

#### Donn√©es d‚Äôentra√Ænement

| Source | Langue | Taille | Particularit√© |
|--------|--------|--------|---------------|
| **EMODIFT** | FR | 3 194 | Annot√© manuellement |
| **TPM-28 / emotion-FR** | FR | 1 839 | Contient la classe *D√©go√ªt* |

Les deux jeux ont √©t√© fusionn√©s puis r√©-√©quilibr√©s pour obtenir exactement **719 exemples / classe**.

#### √âvaluation du mod√®le

| Emotion   | Pr√©cision |
|-----------|-----------|
| Angry     | 0.87      |
| Disgust   | 0.83      |
| Fear      | 0.91      |
| Happy     | 0.93      |
| Neutral   | 0.86      |
| Sad       | 0.94      |
| Surprise  | 0.99      |

**Pr√©cision globale** : **0.90**

![Confusion Matrix](./assets/confusion_matrix_text_model.png)

> Le score de 90 % sur le set de test confirme l‚Äôint√©r√™t du fine-tuning pour ajouter la classe *D√©go√ªt* (vs 82 % avant adaptation).